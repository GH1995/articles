---
title: '狸花猫记(5): 时序差分法'
tags:
  - reinforcement learning
categories:
  - reinforcement learning
date: 2019-07-18 21:55:49
---

蒙特卡罗法需要所有的采样序列都是经历完整的状态序列。如果没有完整的状态序列，那么就无法使用蒙特卡罗法求解了。

## 时序差分TD简介

> 没有完整的状态序列，只有部分的状态序列，那么如何可以近似求出某个状态的收获呢？

参考贝尔曼方程

$$
v_{\pi}(s) = \mathbb{E}_{\pi}(R_{t+1} + \gamma v_{\pi}(S_{t+1}) | S_t=s)
$$

## 时序差分TD的预测问题求解

## $n$步时序差分

## $TD(\lambda)$

## 时序差分的控制问题求解

## 时序差分小结

主流的强化学习方法，是许多方法的基础
