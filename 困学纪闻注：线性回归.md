---
title: 困学纪闻注 ：线性回归
date: 2019-06-19 19:05:58
tags:
    - machine learning
    - todo
---

## 模型

$$
f(\mathbf{x} ; \mathbf{w})=\mathbf{w}^{\mathrm{T}} \mathbf{x}
$$

## 参数学习

### 经验风险最小化

$$
\begin{aligned} \mathcal{R}(\mathbf{w}) &=\sum_{n=1}^{N} \mathcal{L}\left(y^{(n)}, f\left(\mathbf{x}^{(n)}, \mathbf{w}\right)\right) \\ &=\frac{1}{2} \sum_{n=1}^{N}\left(y^{(n)}-\mathbf{w}^{\mathrm{T}} \mathbf{x}^{(n)}\right)^{2} \\ &=\frac{1}{2}\left\|\mathbf{y}-X^{\mathrm{T}} \mathbf{w}\right\|^{2} \end{aligned}
$$

$$
\begin{aligned} \frac{\partial \mathcal{R}(\mathbf{w})}{\partial \mathbf{w}} &=\frac{1}{2} \frac{\partial\left\|\mathbf{y}-X^{\mathrm{T}} \mathbf{w}\right\|^{2}}{\partial \mathbf{w}} \\ &=-X\left(\mathbf{y}-X^{\mathrm{T}} \mathbf{w}\right) \end{aligned}
$$

令$\frac{\partial}{\partial \mathbf{w}} \mathcal{R}(\mathbf{w})=0$，得到
$$
\mathbf{w}^{*}=\left(X X^{\mathrm{T}}\right)^{-1} X \mathbf{y}
$$

$$
\mathbf{w} \leftarrow \mathbf{w}+\alpha X\left(\mathbf{y}-X^{\mathrm{T}} \mathbf{w}\right)
$$

### 结构风险最小化

$$
\mathcal{R}(\mathbf{w})=\frac{1}{2}\left\|\mathbf{y}-X^{\mathrm{T}} \mathbf{w}\right\|^{2}+\frac{1}{2} \lambda\|\mathbf{w}\|^{2}
$$

### 最大似然估计
假设标签$y$为一个随机变量，其服从以均值为$f(\mathbf{x}, \mathbf{w})=\mathbf{w}^{\mathbf{T}} \mathbf{x}$为中心，方差为$\sigma^{2}$的高斯分布。

$$
\begin{aligned} p(y | \mathbf{x}, \mathbf{w}, \sigma) &=\mathcal{N}\left(y | \mathbf{w}^{\mathrm{T}} \mathbf{x}, \sigma^{2}\right) \\ &=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(y-\mathbf{w}^{\mathrm{T}} \mathbf{x}\right)^{2}}{2 \sigma^{2}}\right) \end{aligned}
$$

参数$\mathbf{w}$在训练集上的**似然函数**（likelihood）为
$$
\begin{aligned} p(\mathbf{y} | X, \mathbf{w}, \sigma) &=\prod_{n=1}^{N} p\left(y^{(n)} | \mathbf{x}^{(n)}, \mathbf{w}, \sigma\right) \\ &=\prod_{n=1}^{N} \mathcal{N}\left(y^{(n)} | \mathbf{w}^{\mathrm{T}} \mathbf{x}^{(n)}, \sigma^{2}\right) \end{aligned}
$$


$$
\log p(\mathbf{y} | X, \mathbf{w}, \sigma)=\sum_{n=1}^{N} \log \mathcal{N}\left(y^{(n)} | \mathbf{w}^{\mathrm{T}} \mathbf{x}^{(n)}, \sigma^{2}\right)
$$

$$
\frac{\partial \log p(\mathbf{y} | X, \mathbf{w}, \sigma)}{\partial \mathbf{w}}=0
$$

$$
\mathbf{w}^{M L}=\left(X X^{\mathrm{T}}\right)^{-1} X \mathbf{y}
$$

### 最大后验估计

略，我也不会，贝叶斯好难啊
